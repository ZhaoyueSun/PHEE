{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSample Case For Analysis.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sample Case For Analysis.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "from ast import arguments\n",
    "from tkinter import E\n",
    "import spacy\n",
    "from easydict import EasyDict as edict\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from evaluate.phee_metric import compute_metric\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gold_instances(gold_file):\n",
    "    PARENT_ARGS = ['Subject', \"Effect\", 'Treatment'] # TODO: discard this Disorder after cleaning the data\n",
    "    PARENT_TO_CHILD = {\n",
    "        \"Subject\": [\"Race\", \"Age\", \"Gender\", \"Population\", \"Disorder\"],\n",
    "        \"Treatment\": [\"Duration\", \"Time_elapsed\",\"Route\",\"Freq\",\"Dosage\", \"Disorder\", \"Drug\"],\n",
    "        \"Effect\": [],\n",
    "    }\n",
    "\n",
    "    instances = {}\n",
    "    with open(gold_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "\n",
    "            data = json.loads(line)\n",
    "            data = edict(data)\n",
    "\n",
    "            annotation = data.annotations[0]\n",
    "\n",
    "            instance = defaultdict(list)\n",
    "            instance['context'] = [data.context]\n",
    "\n",
    "            for ev_id, event in enumerate(annotation.events):\n",
    "                # Convert trigger\n",
    "                ev_type = event.event_type\n",
    "                trigger_text = event.Trigger.text[0][0]\n",
    "                instance[ev_type + str(ev_id)+\".Trigger\"].append(trigger_text)\n",
    "\n",
    "                # Convert arguments\n",
    "                for role in PARENT_ARGS:\n",
    "                    if role in event: # not appeared arguments are not stored\n",
    "                        argument = event[role]\n",
    "                        for entities in argument.text: # for each span in a multi-span argument\n",
    "                            for t in entities: # for each discontinuous part of a argument span\n",
    "                                instance[ev_type + str(ev_id)+\".\"+role].append(t)\n",
    "                        # extract sub_arguments information\n",
    "                        for key in argument.keys():\n",
    "                            if key in PARENT_TO_CHILD[role]:\n",
    "                                sub_arg = argument[key]\n",
    "                                for entities in sub_arg.text: # for each span in a multi-span argument\n",
    "                                    for t in entities: # for each discontinuous part of a argument span\n",
    "                                        instance[ev_type + str(ev_id) + \".\"+role+\".\"+key].append(t)\n",
    "\n",
    "                        # extraction combination.drug information\n",
    "                        if role == 'Treatment' and 'Combination' in argument:\n",
    "                            for comb in argument.Combination:\n",
    "                                if \"Drug\" in comb:\n",
    "                                    for entities in comb.Drug.text:\n",
    "                                        for t in entities:\n",
    "                                            instance[ev_type + str(ev_id) +\".Combination.Drug\"].append(t)\n",
    "\n",
    "            instances[data.id] = instance\n",
    "\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_eeqa_preds(pred_file):\n",
    "    instances = {}\n",
    "    with open(pred_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            data = json.loads(line)\n",
    "\n",
    "            sentence = data['sentence']\n",
    "            instance_id = data['id']\n",
    "            instance = []\n",
    "            for entities in data['event']:\n",
    "                event_type = entities[0][2]\n",
    "                for eid, entity in enumerate(entities):\n",
    "                    if eid == 0:\n",
    "                        entity_type = event_type+\".Trigger\"\n",
    "                    else:\n",
    "                        entity_type = event_type+\".\"+entity[2]\n",
    "\n",
    "                    entity_text = \" \".join(sentence[entity[0]:entity[1]+1])\n",
    "                    instance.append([entity_type, entity_text])\n",
    "            for entity in data['arg_pred']:\n",
    "                entity_type = entity[2]\n",
    "                entity_text = \" \".join(sentence[entity[0]:entity[1]+1])\n",
    "                instance.append([entity_type, entity_text])\n",
    "                \n",
    "            instance.sort(key = lambda x:x[0])\n",
    "            instances[instance_id] = instance\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seqlb_preds(pred_file, gold_file):\n",
    "    instance_ids = []\n",
    "    with open(gold_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "\n",
    "            data = json.loads(line)\n",
    "            data = edict(data)\n",
    "            instance_ids.append(data.id)\n",
    "            \n",
    "    PARENT_ARGS = ['Subject', \"Effect\", 'Treatment'] \n",
    "    PARENT_TO_CHILD = {\n",
    "        \"Subject\": [\"Race\", \"Age\", \"Gender\", \"Population\", \"Sub_Disorder\"],\n",
    "        \"Treatment\": [\"Duration\", \"Time_elapsed\",\"Route\",\"Freq\",\"Dosage\", \"Treat_Disorder\", \"Drug\"],\n",
    "    }\n",
    "    SUB_TO_MAIN = {}\n",
    "    for main_arg in PARENT_TO_CHILD:\n",
    "        for sub_arg in PARENT_TO_CHILD[main_arg]:\n",
    "            SUB_TO_MAIN[sub_arg] = main_arg\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(pred_file, 'r') as f:\n",
    "        docs = f.read().strip().split('\\n\\n')\n",
    "\n",
    "    assert(len(docs) == len(instance_ids))\n",
    "    instances = {}\n",
    "    no_event = 0\n",
    "    for sid, sentences in enumerate(docs):\n",
    "        instance_id = instance_ids[sid]\n",
    "        instance = defaultdict(list)\n",
    "        tokens = sentences.split('\\n')\n",
    "        main_entities = []\n",
    "        labels = []\n",
    "        cur_entity = ''\n",
    "        cur_entity_type = 'O'\n",
    "        for token in tokens:\n",
    "            txt, gold, pred, _ = token.split(' ')\n",
    "            labels.append((txt, pred, gold))\n",
    "            if pred != 'O':\n",
    "                pred = pred.split('-',1)[1]\n",
    "                if 'Trigger' not in pred:\n",
    "                    pred = pred.split('.')[0]\n",
    "                    if pred not in PARENT_ARGS:\n",
    "                        pred = 'O'\n",
    "            if pred == cur_entity_type:\n",
    "                cur_entity = cur_entity + ' ' + txt\n",
    "            else:\n",
    "                if cur_entity_type != 'O':\n",
    "                    main_entities.append([cur_entity, cur_entity_type])\n",
    "                cur_entity = txt\n",
    "                cur_entity_type = pred\n",
    "        if cur_entity and cur_entity_type != 'O':\n",
    "            main_entities.append([cur_entity, cur_entity_type])\n",
    "\n",
    "        sub_entities = []\n",
    "        cur_entity = ''\n",
    "        cur_entity_type = 'O'\n",
    "        for token in tokens:\n",
    "            txt, _, pred, _ = token.split(' ')\n",
    "            if pred != 'O':\n",
    "                pred = pred.split('-',1)[1]\n",
    "                if 'Trigger' in pred:\n",
    "                    pred = 'O'\n",
    "                elif pred in PARENT_ARGS:\n",
    "                    pred = 'O'\n",
    "                elif pred == 'Treatment.Combination.Drug':\n",
    "                        pred = 'Combination.Drug'\n",
    "                elif pred in SUB_TO_MAIN:\n",
    "                    pred = SUB_TO_MAIN[pred]+\".\"+pred\n",
    "\n",
    "            pred = pred.replace('Sub_Disorder', 'Disorder')\n",
    "            pred = pred.replace('Treat_Disorder', 'Disorder')\n",
    "            if pred == cur_entity_type:\n",
    "                cur_entity = cur_entity + ' ' + txt\n",
    "            else:\n",
    "                if cur_entity_type != 'O':\n",
    "                    sub_entities.append([cur_entity, cur_entity_type])\n",
    "                cur_entity = txt\n",
    "                cur_entity_type = pred\n",
    "        if cur_entity and cur_entity_type != 'O':\n",
    "            sub_entities.append([cur_entity, cur_entity_type])\n",
    "\n",
    "        # find event_type\n",
    "        event_type = None\n",
    "        for entity, entity_type in main_entities:\n",
    "            if 'Trigger' in entity_type:\n",
    "                event_type = entity_type.split('.')[0]\n",
    "        \n",
    "        if event_type == None:\n",
    "            event_type = 'UNK'\n",
    "            no_event += 1\n",
    "\n",
    "        for entity, entity_type in main_entities + sub_entities:\n",
    "            if 'Trigger' in entity_type:\n",
    "                instance[entity_type].append(entity)\n",
    "            else:\n",
    "                instance[event_type + \".\" + entity_type].append(entity)\n",
    "        instance['labels'] = labels\n",
    "\n",
    "        instances[instance_id] = instance\n",
    "            \n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_entities(text):\n",
    "        EVENT_TYPES = ['Adverse event', 'Potential therapeutic event']\n",
    "        MAIN_ARGS = ['Subject', 'Treatment', 'Effect']\n",
    "        pattern = re.compile(r'\\[.*?\\][^\\[]*')\n",
    "        entities = defaultdict(list)\n",
    "        event = None\n",
    "        for ent_str in re.findall(pattern, text):\n",
    "            k, v = ent_str.split(']', 1)\n",
    "            k = k.replace('[','').strip()\n",
    "            v = v.strip()\n",
    "            if k in EVENT_TYPES:\n",
    "                event = \"_\".join(k.split(' '))\n",
    "                k = event+\".Trigger\"\n",
    "            elif k in MAIN_ARGS:\n",
    "                if event:\n",
    "                    k = event + \".\" + k\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "            if v:\n",
    "                spans = v.split(\";\")\n",
    "                for span in spans:\n",
    "                    entities[k].append(span.strip())\n",
    "\n",
    "        return entities\n",
    "\n",
    "def get_genqa_preds(stage1_file, stage2_file):\n",
    "    instances = defaultdict(dict)\n",
    "    with open(stage1_file, \"r\") as f:\n",
    "        s1_data = json.load(f)\n",
    "        preds = s1_data['predictions']\n",
    "        for pred in preds:\n",
    "            instance_id = \"_\".join(pred['id'].split('_')[:-1])\n",
    "            ents = _parse_entities(pred['prediction_text'])\n",
    "            for k, v in ents.items():\n",
    "                instances[instance_id][k] = v\n",
    "    \n",
    "    with open(stage2_file, \"r\") as f:\n",
    "        s2_data = json.load(f)\n",
    "        labels = s2_data['label_ids']\n",
    "        preds = s2_data['predictions']\n",
    "        for label, pred in zip(labels, preds):\n",
    "            instance_id = \"_\".join(pred['id'].split('_')[:-1])\n",
    "            pred_txt = pred['prediction_text']\n",
    "            pred_type = label['question_type']\n",
    "            if pred_txt: \n",
    "                instances[instance_id][pred_type] = [pred_txt]\n",
    "            \n",
    "    return instances\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        tks = text.split()\n",
    "        tokens = []\n",
    "        for tk in tks:\n",
    "            tmp = \"\"\n",
    "            for ch in tk:\n",
    "                if ch not in exclude:\n",
    "                    tmp += ch\n",
    "                else:\n",
    "                    if tmp:\n",
    "                        tokens.append(tmp)\n",
    "                        tmp = \"\"\n",
    "            if tmp:\n",
    "                tokens.append(tmp)\n",
    "                    \n",
    "        return \" \".join(tokens)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_argument(arg_key, gold_instances, seqlb_preds, eeqa_preds, genqa_preds, query_id=None):\n",
    "\n",
    "    find = False\n",
    "    while not find:\n",
    "        ids = list(gold_instances.keys())\n",
    "        if not query_id:\n",
    "            select_id = ids[random.randint(0, len(ids)-1)]\n",
    "        else:\n",
    "            select_id = query_id\n",
    "        # select_id = '16317298_5'\n",
    "\n",
    "        gold_rst = gold_instances[select_id]\n",
    "        eeqa_rst = eeqa_preds[select_id]\n",
    "        seqlb_rst = seqlb_preds[select_id]\n",
    "        genqa_rst = genqa_preds[select_id]\n",
    "        \n",
    "        gold_span = \"\"\n",
    "        seq_span = \"\"\n",
    "        eeqa_span = \"\"\n",
    "        genqa_span = \"\"\n",
    "        \n",
    "        \n",
    "        for k in gold_rst:\n",
    "            if k.split('.',1)[-1] == arg_key:\n",
    "                gold_span = \"; \".join(gold_rst[k])\n",
    "                \n",
    "        for k in seqlb_rst:\n",
    "            if k.split('.',1)[-1] == arg_key:\n",
    "                seq_span = \"; \".join(seqlb_rst[k])\n",
    "                \n",
    "        for k, v in eeqa_rst:\n",
    "            if k.split('.',1)[-1] == arg_key:\n",
    "                eeqa_span = v\n",
    "                \n",
    "        for k in genqa_rst:\n",
    "            if k.split('.',1)[-1] == arg_key:\n",
    "                genqa_span = \"; \".join(genqa_rst[k])\n",
    "                \n",
    "        if gold_span and (_normalize_answer(gold_span) != _normalize_answer(seq_span) or \\\n",
    "            _normalize_answer(gold_span) != _normalize_answer(eeqa_span) or \\\n",
    "            _normalize_answer(gold_span) != _normalize_answer(genqa_span)):\n",
    "            find = True\n",
    "\n",
    "    if find:\n",
    "        print(\"id: %s\"%select_id)\n",
    "        print(\"sentence:\")\n",
    "        print(gold_rst['context'][0])\n",
    "        print(\"\\ngold:\")\n",
    "        for k in gold_rst:\n",
    "            if k.split('.',1)[-1] == arg_key:\n",
    "                print(k, \":\", \"; \".join(gold_rst[k]))\n",
    "                \n",
    "        print(\"\\nseq labelling: \")\n",
    "        for k in seqlb_rst:\n",
    "            if k.split('.',1)[-1] == arg_key:\n",
    "                print(k, \":\", \"; \".join(seqlb_rst[k]))\n",
    "\n",
    "        print(\"\\neeqa:\")\n",
    "        for k, v in eeqa_rst:\n",
    "            if k.split('.',1)[-1] == arg_key:\n",
    "                print(k, \":\", v)\n",
    "                \n",
    "        print(\"\\ngenqa:\")\n",
    "        for k in genqa_rst:\n",
    "            if k.split('.',1)[-1] == arg_key:\n",
    "                print(k, \":\", \"; \".join(genqa_rst[k]))\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3048532/275472726.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m            \"../gen_qa/model/stage2/SciFive-base-PMC/5/predict_outputs.json\")\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcheck_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Subject.Disorder'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_instances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlb_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meeqa_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenqa_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3048532/284527306.py\u001b[0m in \u001b[0;36mcheck_argument\u001b[0;34m(arg_key, gold_instances, seqlb_preds, eeqa_preds, genqa_preds, select_id)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgold_rst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0marg_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mgold_span\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"; \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_rst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gold_file = \"../data/json/test.json\"\n",
    "gold_instances = get_gold_instances(gold_file)\n",
    "\n",
    "seqlb_preds = get_seqlb_preds('../data/ace/test_pred_ace.tsv',  \"../data/json/test.json\")\n",
    "\n",
    "eeqa_pred_file = \"../eeqa/model/biobert_rst/stage2/1/pred_outputs.json\"\n",
    "eeqa_preds = get_eeqa_preds(eeqa_pred_file)\n",
    "\n",
    "genqa_preds = get_genqa_preds(\"../gen_qa/model/stage1/SciFive-base-PMC/predict_outputs.json\",\n",
    "           \"../gen_qa/model/stage2/SciFive-base-PMC/5/predict_outputs.json\")\n",
    "\n",
    "check_argument('Subject.Disorder', gold_instances, seqlb_preds, eeqa_preds, genqa_preds, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Adverse_event.Combination.Drug', 'triamcinolone'],\n",
       " ['Adverse_event.Effect', \"severe iatrogenic Cushing 's syndrome\"],\n",
       " ['Adverse_event.Subject', 'she'],\n",
       " ['Adverse_event.Subject.Gender', 'she'],\n",
       " ['Adverse_event.Treatment',\n",
       "  \"Forty - one days later , she developed severe iatrogenic Cushing 's syndrome due to the drug - drug interaction between triamcinolone and her boosted protease inhibitor therapy\"],\n",
       " ['Adverse_event.Treatment.Drug', 'triamcinolone'],\n",
       " ['Adverse_event.Trigger', 'developed']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeqa_preds['23970584_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adverse_event.Trigger': ['resulted'],\n",
       " 'Adverse_event.Subject': ['case 1, a total daily dose of 25 mg sertraline'],\n",
       " 'Adverse_event.Effect': ['a doubling of the lamotrigine blood level with symptoms of toxicity']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genqa_preds['9627209_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'S-Subject', 'S-Subject'),\n",
       " ('77', 'B-Subject.Age', 'B-Subject.Age'),\n",
       " ('-', 'I-Subject.Age', 'I-Subject.Age'),\n",
       " ('year', 'I-Subject.Age', 'I-Subject.Age'),\n",
       " ('-', 'I-Subject.Age', 'I-Subject.Age'),\n",
       " ('old', 'E-Subject.Age', 'E-Subject.Age'),\n",
       " ('woman', 'S-Subject.Gender', 'S-Subject.Gender'),\n",
       " ('with', 'B-Subject', 'S-Subject'),\n",
       " ('no', 'I-Subject', 'B-Subject.Sub_Disorder'),\n",
       " ('history', 'I-Subject', 'I-Subject.Sub_Disorder'),\n",
       " ('of', 'E-Subject', 'I-Subject.Sub_Disorder'),\n",
       " ('epilepsy', 'S-Subject.Sub_Disorder', 'E-Subject.Sub_Disorder'),\n",
       " ('presented', 'S-Adverse_event.Trigger', 'O'),\n",
       " ('a', 'O', 'B-Effect'),\n",
       " ('probable', 'B-Effect', 'I-Effect'),\n",
       " ('nonconvulsive', 'I-Effect', 'I-Effect'),\n",
       " ('status', 'I-Effect', 'I-Effect'),\n",
       " ('epilepticus', 'E-Effect', 'E-Effect'),\n",
       " ('while', 'O', 'O'),\n",
       " ('receiving', 'S-Adverse_event.Trigger', 'S-Adverse_event.Trigger'),\n",
       " ('continuous', 'S-Treatment', 'S-Treatment.Freq'),\n",
       " ('intravenous', 'S-Treatment.Route', 'S-Treatment.Route'),\n",
       " ('morphine', 'S-Treatment.Drug', 'S-Treatment.Drug'),\n",
       " ('for', 'O', 'O'),\n",
       " ('back', 'B-Treat_Disorder', 'B-Treat_Disorder'),\n",
       " ('pain', 'I-Treat_Disorder', 'I-Treat_Disorder'),\n",
       " ('relating', 'I-Treat_Disorder', 'I-Treat_Disorder'),\n",
       " ('to', 'I-Treat_Disorder', 'I-Treat_Disorder'),\n",
       " ('vertebral', 'I-Treat_Disorder', 'I-Treat_Disorder'),\n",
       " ('metastasis', 'I-Treat_Disorder', 'I-Treat_Disorder'),\n",
       " ('of', 'I-Treat_Disorder', 'I-Treat_Disorder'),\n",
       " ('a', 'I-Treat_Disorder', 'I-Treat_Disorder'),\n",
       " ('malignant', 'I-Treat_Disorder', 'I-Treat_Disorder'),\n",
       " ('lymphoma', 'E-Treat_Disorder', 'E-Treat_Disorder'),\n",
       " ('.', 'O', 'O')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqlb_preds['10812579_1']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754 patients or 18 years with severe sepsis and high inr\n",
      "1754 patients or 18 years with severe sepsis and high inr or 1 2 201 patients with low inr 1 2\n"
     ]
    }
   ],
   "source": [
    "print(_normalize_answer(\"1754 patients (> or =18 years) with severe sepsis and a high INR\"))\n",
    "print(_normalize_answer(\"1754 patients ( > or = 18 years ) with severe sepsis and a high INR ( > or = 1.2 ); 201 patients with a low INR ( < 1.2 )\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'context': ['We report four cases of encephalopathy coincident with elevated aluminum levels as well as one patient who developed seizures while receiving continuous bladder irrigations with alum.'],\n",
       "             'Adverse_event0.Trigger': ['developed'],\n",
       "             'Adverse_event0.Subject': ['one patient'],\n",
       "             'Adverse_event0.Subject.Population': ['one'],\n",
       "             'Adverse_event0.Effect': ['seizures'],\n",
       "             'Adverse_event0.Treatment': ['receiving continuous bladder irrigations with alum'],\n",
       "             'Adverse_event0.Treatment.Drug': ['alum']})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_instances['1422497_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9120c2ad493f685658d4a19c07d0b339b1f9dc268ca12ff6043adf0585046beb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
